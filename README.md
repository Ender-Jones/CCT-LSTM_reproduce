# CCT-LSTM_reproduce

## How to replicate the environment?

```bash
conda env create -f environment.yml
conda activate cctlstm

python - <<'PY'
import sys, torch, torchvision, cv2, mediapipe as mp, numpy as np, PIL
print("python", sys.version.split()[0])
print("torch", torch.__version__, "cuda", torch.cuda.is_available())
print("torchvision", torchvision.__version__)
print("cv2", cv2.__version__)
print("mediapipe", mp.__version__)
print("numpy", np.__version__, "pillow", PIL.__version__)
PY
```

## `main.py`: Pipeline Orchestrator

This script serves as the main entry point for the entire data processing pipeline. It uses command-line arguments to
execute different stages of the process.

### Pipeline Workflow

The pipeline is divided into three main steps, which should be run in order.

1. **`check`**: Runs the dataset integrity check and creates the master manifest. This step is mandatory before
   proceeding.
   ```bash
   python main.py check
   ```
2. **`extract`**: Extracts facial landmarks from all videos.
   ```bash
   python main.py extract
   ```
3. **`process`**: Processes the extracted landmarks into MTF (Markov Transition Field) images.
   ```bash
   python main.py process
   ```

## `integrity_and_masterManifest.py`

### Check the integrity of UBFC-Phys dataset by the following logic:

1. In selected folder, if "UBFC-Phys" folder exists, then it will be used as the dataset.
2. In "UBFC-Phys", if "Data" folder exists.
3. If there are 56 folders named "s1(subject number)", "s2", ..., "s56" in "Data" folder.
4. For each subject folder:
    1. if there are 3 avi files named "vid_s1(subject number)_1.avi", "vid_s1_2.avi", "vid_s1_3.avi".
    2. if there are 3 csv files named "bvp_s1(subject number)_T1.csv", "bvp_s1_T2.csv", "bvp_s1_T3.csv".
    3. if there are 3 csv files named "eda_s1(subject number)_T1.csv", "eda_s1_T2.csv", "eda_s1_T3.csv".
    4. if there is 1 txt file named "info_s1(subject number).txt".
    5. if there is 1 csv file named "selfReportedAnx_s1(subject number).csv".
       If any of the above conditions are not met, it will print an error message and exit.

### Known Dataset Discrepancies

> [!WARNING]
> During our integrity check, we identified the following issues with the official UBFC-Phys dataset downloaded
from [dat@UBFC](https://search-data.ubfc.fr/FR-18008901306731-2022-05-05_UBFC-Phys-A-Multimodal-Dataset-For.html):
> - **Error in `s40`**: The file `vid_s40_T3.avi` is missing. This appears to be a naming error within the dataset
    itself.
> - **Error in `s56`**: The file `selfReportedAnx_s56.csv` is missing. We also noted that the self-report data in
    `s55` & `s56` are identical. As this self-report data is not utilized in our project, we have chosen to ignore this
    discrepancy.

### After integrity check, it will generate a master manifest file named "masterManifest.csv" in the selected folder.

The master manifest file will contain the following columns:

- subject: subject number
- group: 'test' or 'ctrl'

## `file_path_gen.py`

### Generate the file paths for the UBFC-Phys dataset.

The path will be based on "UBFC_data_path.txt" generated by `integrity_and_masterManifest.py` in the project root
directory.  
The dataset is organized as the following structure:  
![structure.png](imgs/structure.png)

### xxx(parent folder)/UBFC-Phys/Data/s1(subject folder)/vid_s1_1.avi etc.

## TODO: 模型实现路线图

### 阶段一：预训练 CCT 特征提取器

**目标**：分别训练两个CCT模型（Landmark 和 rPPG），让它们学会从单张MTF图中提取与压力相关的特征。

1. **`dataset.py`**:
    * 实现 `SingleImageDataset` 类。
    * 工作模式为“图片模式”，每次返回**一张**MTF图及其对应的标签（如 T1, T2, T3）。
    * 需要能够配置为只加载 `landmark` 或只加载 `rppg` 的图像数据。

2. **`model.py` (初版)**:
    * 创建 `CCTForPreTraining` 模型。
    * 模型结构：`vit-pytorch` 的 `CCT` 实例。
    * 通过设置 `num_classes` 参数，`vit-pytorch` 会自动附加一个用于分类的MLP头。

3. **`train_cct.py`**:
    * 专门用于阶段一的训练脚本。
    * 使用 `SingleImageDataset` 加载数据。
    * 创建 `CCTForPreTraining` 模型的实例。
    * 实现标准的图像分类训练和验证循环。
    * 在每个交叉验证折叠中，保存验证集上表现最佳的模型权重（`state_dict`）。为 `landmark` 和 `rppg` 分别保存一套权重。

### 阶段二：训练完整的 CCT-LSTM 模型

**目标**：加载预训练好的CCT权重，并训练整个端到端的序列模型。

1. **`dataset.py` (扩展)**:
    * 实现 `VideoSequenceDataset` 类。
    * 工作模式为“序列模式”，每次返回**一整个视频**的所有窗口数据（即N对MTF图的序列）及其唯一标签。

2. **`model.py` (最终版)**:
    * 创建 `CCT_LSTM_Model` 类。
    * 模型结构：
        * 两个不含分类头的 `CCT` 实例。
        * 一个 `nn.LSTM` 层。
        * 一个最终的 `nn.Linear` 分类头。
    * 实现 `load_pretrained_weights` 方法，从阶段一保存的权重中加载CCT主体的参数。

3. **`train_full.py`**:
    * 用于阶段二的主训练脚本。
    * 使用 `VideoSequenceDataset` 加载序列数据。
    * 创建 `CCT_LSTM_Model` 实例并加载预训练权重。
    * 实现序列模型的训练循环，对整个模型（包括CCT和LSTM）进行微调。

## 当前进度表（工程视角）

- [x] 数据路径/清单：`python main.py check` 生成 `master_manifest.csv` 与 `UBFC_data_path.txt`
- [x] Landmark/rPPG JSON：已就绪（rPPG 基于外部 pyVHR，见 `rppg_extractor.py` 顶部说明）
- [x] MTF 生成：两模态均已生成至 `mtf_images/{modality}/`（统一 z-score，quantile+n_bins=8）
- [x] 对齐核验：`verify_landmarks_vs_rppg.py` 已跑；168 对中仅 `s12/T2` 不一致（接受，按窗口 ID 交集 + `MIN_SEQ_LENGTH=10` 配对）
- [x] Stage 1（单模态 CCT，7 折）：
  - Landmark 平均 macro-F1≈0.610；rPPG 平均 macro-F1≈0.648
  - 产物：`weights/cct_{modality}_fold_*_best.pth`
- [x] Stage 2（任务三分类，7 折）：
  - 方案A：早停（patience=15）已完成，首折 val_f1≈0.598；各折报告见 `reports/tasks/fold_*/`
  - 方案B：固定 100 epoch（无早停）复现实验：已启动/正在运行（产物覆盖到相同 `reports/tasks/` 目录）
- [ ] Stage 2（多等级，5 折）：固定 100 epoch（无早停）运行中，报告将落到 `reports/levels/fold_*/`
- [ ] 结果汇总：两实验的均值指标、每折混淆矩阵与 per-class PRF，整理到 README“结果”章节

## 一键运行（Stage 2）

1) 任务三分类（T1/T2/T3，7 折）
```bash
python train_cct_lstm.py --device cuda --num_workers 4
# 复现论文表格风格：固定 100 epoch
python train_cct_lstm.py --epochs 100 --early-stop-patience 0 --device cuda --num_workers 4
```

2) 多等级（T1、T3-ctrl、T3-test，5 折分层）
```bash
python train_cct_lstm_levels.py --device cuda --num_workers 4
# 复现论文表格风格：固定 100 epoch
python train_cct_lstm_levels.py --epochs 100 --early-stop-patience 0 --device cuda --num_workers 4
```

说明：
- 两脚本自动按“折内对应”加载 Stage1 权重（fold-k 对应 `cct_landmark_fold_k_best.pth` 与 `cct_rppg_fold_k_best.pth`）。
- 数据根默认读取 `UBFC_data_path.txt`，无需额外参数。
- 评估产物（混淆矩阵/分类报告）保存至 `reports/tasks|levels/fold_*/`。

## 已知注意事项

- `s12/T2` 窗口数不一致：不影响训练（按交集配对）。如需严格一致可后续重导。
- 文件命名需满足 `vid_{subject}_{level}*.json`，代码通过 `stem.split('_')[2]` 解析 level。
- 初期训练可能出现类预测塌缩（macro-F1≈0.1667），训练继续/增大耐心值后通常恢复并提升。
- 为避免信息泄漏：早停应使用训练折内再划分的验证集；若用测试折做早停将高估结果。要对齐论文表格，建议固定 100 epoch 无早停。